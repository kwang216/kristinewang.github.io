---
title: "Project 2"
author: "Kristine Wang, klw3685"
date: ""
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction 

This is the 'meterorites' dataset, which is a dataset containing information about meteorites and where they fell. This dataset was obtained from the meteoritical soceity by NASA. It contains the variables: name, id, name_type, class, mass, fall year, lat, long, and geolocation of the meteorites. 

MNOVA TESTING
```{r cars}
library(mvtnorm)
library(ggExtra)
library(dplyr)
library(tidyverse)
library(lmtest)

#install.packages('glmnet')
library(glmnet)
meteorites<- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-06-11/meteorites.csv") %>% na.omit

ggplot(meteorites, aes(x=year, y=mass))+ geom_point(alpha=0.5)+ geom_density_2d(h=2)+ coord_fixed()+ facet_wrap(~fall)

```

```{R}
man1<- manova(cbind(year,mass)~fall, data=meteorites)
summary(man1)

summary.aov(man1)

meteorites %>% group_by(fall) %>% summarize(mean(year), mean(mass))

pairwise.t.test(meteorites$year, meteorites$fall, p.adj= "none")

pairwise.t.test(meteorites$mass, meteorites$fall, p.adj="none")

1- (0.95^4) #probability of at least one type I error 

0.05/7 # boneferroni correction 
```
The one-way multivariate analysis of variance (MANOVA) was conducted in order to determine the effects of meteorite type (fell or found) on two variables (mass and year). Based on the MANOVA test, there were significant difference found between the two meteorite types, Pillai trace= 0.2588, pseudoF (2,38112)= 6653.7, pv<0.0001. Univariate analyses of variance for each variable were conducted as follow up test to the MANOVA. The univariate ANOVAs for year was significant with p<0.001. The univariate ANOVAs for mass was not singificant with p>0.05. The found and fell groups differ based on year, but not mass. 

From the MANOVA, ANOVA, and t tests, a=0.05/7 as significance level is 0.007142857. The year is still significant, while the mass is not. There are several assumptions including multivariate normality, equal corvariance between two dependent variables, linear regression among variables, no extreme univariate or multivariate outliers, and no multicollinearity. It is likely that not all assumptions are met. 


## Randomization Test 

```{R}
fall_type<- meteorites %>% dplyr::select(fall, mass)
head(fall_type)

ggplot(fall_type, aes(mass, fill=fall))+ geom_histogram(bins= 6.5)+ facet_wrap(~fall, ncol=2)

fall_type %>% group_by(fall) %>% summarize(means=mean(mass)) %>% summarize(mean_diff= diff(means))

rand_dist<- vector()
for (i in 1:5000){
  new<- data.frame(mass= sample(fall_type$mass), fall_type= fall_type$fall)
  rand_dist[i]<- mean(new[new$fall_type=="Fell",]$mass)
  mean(new[new$condition=="Found",]$mass)
}

{
  hist(rand_dist, main= "", ylab="")
  abline(v= -32822.54, col="red")
}

mean(rand_dist> 32822.54)*2 # P-value
```
Null Hypothesis: Mean mass is the same for fall_type(fell vs found) meteorites. Alternative Hypothesis: mean mass is not the same for fall_type(fell vs. found) meteorites. Based on this test, we fial to reject the null hypothesis. There is a probability of 0.279 to get a mean difference if the outcome data was split into every possible random grouping. 


## Linear Regression 

```{R}
meteorites$lat_c<- meteorites$lat- mean(meteorites$lat)
meteorites$long_c<- meteorites$long- mean(meteorites$long)

fit1<- lm(mass~ lat_c+ long_c, data= meteorites)

summary(fit1)

ggplot(meteorites, aes(y=long_c, x=lat_c, color=mass))+ geom_point()+ stat_smooth(method= "lm", se= FALSE)

ggplot(meteorites, aes(y=mass, x=long_c))+ geom_point()+ stat_smooth(method= "lm", se= FALSE)

ggplot(meteorites, aes(y=mass, x=lat_c))+ geom_point()+ stat_smooth(method= "lm", se= FALSE)

qqnorm(meteorites$lat_c)

qqnorm(meteorites$long_c)

shapiro.test(head(meteorites$lat_c))

shapiro.test(head(meteorites$long_c))

bptest(fit1) #tesing heteroskedasticity assumption 

library(sandwich)
coeftest(fit1, vcov= vcovHC(fit1))

summary(fit1)$r.sq

fit5<- lm(mass~lat, data=meteorites) #main effects of lat 
summary(fit5)

fit6<- lm(mass~long, data=meteorites) #main effects of long 
summary(fit6)

#install.packages('interactions')
library(interactions)

interact_plot(fit1, lat_c, long_c) #interaction plot

```
For each one unit increase in mass, the latitude increases by 341.81. units and the longitude decreases by 54.17 units. The linearity assumption is violated based on the ggplot. There does seem to be a normality based on the qq plots. The Shapiro-Wilk, the p value >0.05 implies that the distritubion of the data are not significantly different from normal distribution. In other words, we can assume the normality. Bresch-Paga test, the p value <0.05 indicates that the null hypothesis can not be rejecte and therefore heterscedasticity does not exist. Both the t values and the p values decrease. The proportion of the variation in the outcome explained by this model is 0.000886. 


## Regression with Interaction 

```{R}
fit2<- lm(mass~lat*long, data=meteorites)
boot_sd<- meteorites[sample(nrow(meteorites), replace = TRUE),]

samp_distn<- replicate(1000,{
  boot_sd<- meteorites[sample(nrow(meteorites), replace = TRUE),]
  fit3<- lm(mass~lat*long, data=boot_sd)
  coef(fit3)
})

samp_distn %>% t %>% as.data.frame %>% summarize_all(sd)

summary(fit2)

coeftest(fit2, vcov= vcovHC(fit2)) #corrected SEs 
```
The p value of the corrected SEs are higher than the p-values of the uncorrected ones. Additionally the std. errors for the corrected SEs are also higher than the uncorrected ones. 

##Logistic Regression 
```{R}
meteorites$y<- ifelse(meteorites$fall=="Found", 1,0)
fit3<- glm(y~year+ name_type, data=meteorites, family = "binomial")
coeftest(fit3)

exp(coef(fit3))

meteorites$prob<- predict(fit3, type = "response") #save predicted prob 
table(predict= as.numeric(meteorites$prob> 0.5), truth= meteorites$y) %>% addmargins()


36850/37050 #TPR 

313/1065 #TNR 

36850/37602 #PPV 

pca1<- princomp(meteorites[c("year","mass")])
meteorites$predictor<- pca1$scores[,1]
ggplot(meteorites, aes(predictor, prob))+ geom_point(aes(color=fall), alpha= 0.5, size=3)

ggplot(meteorites)+ geom_density(aes(prob, fill=y))+ xlab("logit") #plot density of log-odds by binary outcome variable 


sens<- function(p, data=meteorites, y=y) mean(meteorites[meteorites$y== 1, ]$prob>p)
spec<- function(p, data=meteorites, y=y) mean(meteorites[meteorites$y== 0, ]$prob<p)

sensitivity<- sapply(seq(0,1,0.01), sens, meteorites)
specificity<- sapply(seq(0,1,0.01), spec, meteorites)

ROC1<- data.frame(sensitivity, specificity, cutoff= seq(0, 1, 0.01))
ROC1 %>% gather(key, rate, -cutoff) %>% ggplot(aes(cutoff, rate, color=key))+ geom_path() %>% geom_vline(xintercept= c(0.1, 0.5), lty=2, color="gray50")
#?? 

ROC1$TPR<- sensitivity
ROC1$FPR<- 1- sensitivity
#ROC1%>%ggplot(aes(FPR,TPR))+geom_path(size=1.5)+geom_segment(aes(x=0,y=0,xend=1,yend=1),scale_x_continuous(limits = c(0,1))
ROC1 %>% ggplot(aes(FPR, TPR))+ geom_path(size=1.5)+ geom_segment(aes(x=0, y=0, xend=1, yend=1),lty=2)+ scale_x_continuous(limits = c(0,1))

library(plotROC)
ROCplot<- ggplot(meteorites)+ geom_roc(aes(d=y, m=predictor), n.cuts = 0)
calc_auc(ROCplot) #AUC


```


```{R}
class_diag<- function(probs, truth){
  tab<- table(factor(probs>0.5, levels= c("FALSE", "TRUE")), truth)
  acc= sum(diag(tab))/sum(tab)
  sens= tab[2,2]/colSums(tab)[2]
  spec= tab[1,1]/colSums(tab)[1]
  ppv= tab[2,2]/ rowSums(tab)[2]
  
  if(is.numeric(truth) == FALSE & is.logical(truth)== FALSE) 
    truth<- as.numeric(truth)-1
  
  #calculate exact auc 
  ord<- order(probs, decreasing= TRUE)
  probs<- probs[ord]
  truth<- truth[ord]
  
  TPR= cumsum(truth)/ max(1,sum(truth))
  FPR= cumsum(!truth)/max(1,sum(!truth))
  
  dup<- c(probs[-1] >= probs[-length(probs)], FALSE)
  TPR<- c(0,TPR[!dup],1)
  FPR<- c(0,FPR[!dup],1)
  
  n<- length(TPR)
  auc<- sum(((TPR[-1]+ TPR[-n])/2)*(FPR[-1]-FPR[-n]))
  
  data.frame(acc,sens, spec, ppv, auc)
}

k=10
data1<- meteorites[sample(nrow(meteorites)),]
folds<- cut(seq(1:nrow(meteorites)), breaks=k, labels = F)

# diags<- NULL
# for (i in 1:k){
#   train<- data1[folds != i,]
#   test<- data1[folds==i,]
#   truth<- test$y
#   fit<- glm(y~year+ name_type, data=train, family= "binomial")
#   probs<- predict(fit, newdata=test, type= "response")
#   diags<- rbind(diags, class_diag(probs, truth))
# 
# }
# 
# apply(diags, 2, mean)


```
Based on the logic regression, the odds of being 'found' is 



##LASSO Regression 
```{R}
fit8<- glm(y~  name_type+mass+lat+long, data=meteorites, family = binomial)

x<- model.matrix(fit8)
y<- as.matrix(meteorites$y)
cv<- cv.glmnet(x,y, family="binomial")
lasso1<- glmnet(x,y, family="binomial", lambda = cv$lambda.1se)
coef(lasso1)

prob<- predict(lasso1, newx= x, type="response")
class_diag(prob, meteorites$y)

k=10 
meteorites$valid<- x[, "name_typeValid"]
data2<- meteorites[sample(nrow(meteorites)),]
folds2<-cut(seq(1:nrow(meteorites)), breaks=k, labels=F)

diags<- NULL
for(i in 1:k){
  train<- data2[folds2!=i, ]
  test<- data2[folds2==i, ]
  truth<- test$y
  fit<- glm(y~ valid+ lat+long, data=train, family = "binomial")
  probs<- predict(fit, newdata=test, type= "response")
  diags<- rbind(diags, class_diag(probs, truth))
  
}

apply(diags,2, mean)

summary(fit8)

```
The variables 'name_type', 'lat', and 'long' are retained. The acc, sens, spec, and ppv are lower when compared to the logistic regression. The AUC is higher when compared to the logistic regression above. The residual standard error is 6523.7. 
```{R}



```



